{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid World Enviroment setting\n",
    "* states, actions, transition probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set state\n",
    "import numpy as np\n",
    "nCols = 3\n",
    "nRows = 4\n",
    "nWalls = 1\n",
    "states = []\n",
    "for i in range(nCols*nRows-nWalls):\n",
    "    states.append(i)\n",
    "N_STATES = len(states)\n",
    "\n",
    "terminal_state = [3,6]\n",
    "win_state = [3]\n",
    "lose_state = [6]\n",
    "start_state = [x for x in states if x not in terminal_state]\n",
    "#print(N_STATES)\n",
    "#print(states)\n",
    "\n",
    "# set map\n",
    "map = -np.ones((nCols+2,nRows+2))\n",
    "for i in range(nCols):\n",
    "    for j in range(nRows):\n",
    "        map[i+1,j+1] = 0\n",
    "map[2,2] = -1 # add wall\n",
    "#print(map)\n",
    "\n",
    "# set action\n",
    "actions = [0, 1, 2, 3]\n",
    "N_ACTIONS = len(actions)\n",
    "\n",
    "# states -> location\n",
    "locations = []\n",
    "index = 0\n",
    "for i in range(nCols):\n",
    "    for j in range(nRows):\n",
    "        if map[i+1,j+1]==0:\n",
    "            locations.append((i+1,j+1))\n",
    "            index = index + 1\n",
    "#print(locations) # match index with states\n",
    "# action -> move\n",
    "move = [(0,-1),(-1,0),(0,1),(1,0)] # match index with actions\n",
    "#print(move)\n",
    "\n",
    "# set transition probability\n",
    "P = np.zeros((N_STATES,N_ACTIONS,N_STATES)) # P[S,A,S']\n",
    "for s in range(N_STATES):\n",
    "    for a in range(N_ACTIONS):\n",
    "        current_location = locations[s]\n",
    "        # heading collectly  ####################################################################################\n",
    "        next_location = (current_location[0] + move[a][0],current_location[1] + move[a][1])\n",
    "        \n",
    "        if map[next_location[0],next_location[1]] == -1: # there is barrier or wall\n",
    "            next_location = current_location\n",
    "            next_s = states[locations.index(next_location)]\n",
    "        else:\n",
    "            next_s = states[locations.index(next_location)]\n",
    "        P[s,a,next_s] = P[s,a,next_s] + 0.8\n",
    "        # left error ############################################################################################\n",
    "        next_location = (current_location[0] + move[a-1][0],current_location[1] + move[a-1][1])\n",
    "        if map[next_location[0],next_location[1]] == -1: # there is barrier or wall\n",
    "            next_location = current_location\n",
    "            next_s = states[locations.index(next_location)]\n",
    "        else:\n",
    "            next_s = states[locations.index(next_location)]\n",
    "        P[s,a,next_s] = P[s,a,next_s] + 0.1\n",
    "        # right error ############################################################################################\n",
    "        next_location = (current_location[0] + move[(a+1)%4][0],current_location[1] + move[(a+1)%4][1])\n",
    "        \n",
    "        if map[next_location[0],next_location[1]] == -1: # there is barrier or wall\n",
    "            next_location = current_location\n",
    "            next_s = states[locations.index(next_location)]\n",
    "        else:\n",
    "            next_s = states[locations.index(next_location)]\n",
    "        P[s,a,next_s] = P[s,a,next_s] + 0.1\n",
    "        \n",
    "# rewards s,a ---  R(s,a)  ---> s'\n",
    "if True:\n",
    "    R = -0.02*np.ones((N_STATES,N_ACTIONS))\n",
    "else:\n",
    "    R = -0.5*np.ones((N_STATES,N_ACTIONS))\n",
    "R[3,:] = 1\n",
    "R[6,:] = -1\n",
    "#print(R)\n",
    "# discount factor\n",
    "gamma = 0.99\n",
    "\n",
    "# policy : given state which action would u choose\n",
    "# assume that we know the policy\n",
    "bad_policy = np.zeros((N_STATES,N_ACTIONS))\n",
    "bad_policy[0,2] = 1\n",
    "bad_policy[1,2] = 1\n",
    "bad_policy[2,2] = 1\n",
    "bad_policy[3,2] = 1\n",
    "bad_policy[4,3] = 1\n",
    "bad_policy[5,2] = 1\n",
    "bad_policy[6,2] = 1\n",
    "bad_policy[7,2] = 1\n",
    "bad_policy[8,2] = 1\n",
    "bad_policy[9,2] = 1\n",
    "bad_policy[10,1] = 1\n",
    "\n",
    "random_policy = 0.25*np.ones((N_STATES,N_ACTIONS))\n",
    "\n",
    "optimal_policy = np.zeros((N_STATES,N_ACTIONS))\n",
    "optimal_policy[0,2] = 1\n",
    "optimal_policy[1,2] = 1\n",
    "optimal_policy[2,2] = 1\n",
    "optimal_policy[3,2] = 1\n",
    "optimal_policy[4,1] = 1\n",
    "optimal_policy[5,1] = 1\n",
    "optimal_policy[6,1] = 1\n",
    "optimal_policy[7,1] = 1\n",
    "optimal_policy[8,0] = 1\n",
    "optimal_policy[9,0] = 1\n",
    "optimal_policy[10,0] = 1\n",
    "#print(optimal_policy)\n",
    "\n",
    "optimalWithNoise_policy = np.zeros((N_STATES,N_ACTIONS))\n",
    "ep = 0.1\n",
    "optimalWithNoise_policy[0,2] = 1\n",
    "optimalWithNoise_policy[1,2] = 1\n",
    "optimalWithNoise_policy[2,2] = 1\n",
    "optimalWithNoise_policy[3,2] = 1\n",
    "optimalWithNoise_policy[4,1] = 1\n",
    "optimalWithNoise_policy[5,1] = 1\n",
    "optimalWithNoise_policy[6,1] = 1\n",
    "optimalWithNoise_policy[7,1] = 1\n",
    "optimalWithNoise_policy[8,0] = 1\n",
    "optimalWithNoise_policy[9,0] = 1\n",
    "optimalWithNoise_policy[10,0] = 1\n",
    "optimalWithNoise_policy = optimalWithNoise_policy + (ep/4)*np.ones((N_STATES,N_ACTIONS))\n",
    "optimalWithNoise_policy = optimalWithNoise_policy / np.sum(optimalWithNoise_policy,axis = 1).reshape((N_STATES,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every visit Monte Carlo Policy Evaluation\n",
    "* Function Approximation(linear combination)\n",
    "$$V(s) = X(s)^{T}w$$\n",
    "* loss function\n",
    "$$J(w) = E_{\\pi}[(G_{t}\\:-\\:X(s)^{T}w)^{2}]$$\n",
    "* gradient descent\n",
    "$$\\nabla_{w}J(w) = -2\\:*\\:E_{\\pi}[(G_{t}\\:-\\:X(s)^{T}w)]\\:*\\:X(s)$$\n",
    "* stochastic gradient descent(batch size 1)\n",
    "$$\\nabla_{w}J(w) = -2\\:*(G_{t}\\:-\\:X(s)^{T}w)\\:*\\:X(s)$$\n",
    "* update parameter vector w\n",
    "$$\\Delta w = \\alpha\\:*\\:(G_{t}\\:-\\:X(s)^{T}w)*X(s) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : \n",
      "1.15.0\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation W/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node node W/Initializer/random_uniform/RandomUniform (defined at /home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) placed on device Device assignments active during op 'W/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:1816>\n  with tf.device(/GPU:0): <<ipython-input-9-298df1d72c53>:18>  was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssign: CPU \nApplyGradientDescent: CPU \nRandomUniform: CPU XLA_CPU XLA_GPU \nConst: CPU XLA_CPU XLA_GPU \nMul: CPU XLA_CPU XLA_GPU \nSub: CPU XLA_CPU XLA_GPU \nAdd: CPU XLA_CPU XLA_GPU \nIdentity: CPU XLA_CPU XLA_GPU \nVariableV2: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  W/Initializer/random_uniform/shape (Const) \n  W/Initializer/random_uniform/min (Const) \n  W/Initializer/random_uniform/max (Const) \n  W/Initializer/random_uniform/RandomUniform (RandomUniform) \n  W/Initializer/random_uniform/sub (Sub) \n  W/Initializer/random_uniform/mul (Mul) \n  W/Initializer/random_uniform (Add) \n  W (VariableV2) /device:GPU:0\n  W/Assign (Assign) /device:GPU:0\n  W/read (Identity) /device:GPU:0\n  GradientDescent/update_W/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n\n\t [[node W/Initializer/random_uniform/RandomUniform (defined at /home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]Additional information about colocations:No node-device colocations were active during op 'W/Initializer/random_uniform/RandomUniform' creation.\nDevice assignments active during op 'W/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:1816>\n  with tf.device(/GPU:0): <<ipython-input-9-298df1d72c53>:18>\n\nOriginal stack trace for 'W/Initializer/random_uniform/RandomUniform':\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-298df1d72c53>\", line 26, in <module>\n    initializer=tf.random_uniform_initializer(-1.0,1.0))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n    shape=shape)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n    shape=shape)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 1818, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 905, in <lambda>\n    partition_info=partition_info)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py\", line 283, in __call__\n    shape, self.minval, self.maxval, dtype, seed=self.seed)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/random_ops.py\", line 245, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_random_ops.py\", line 822, in random_uniform\n    name=name)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation W/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node {{colocation_node W/Initializer/random_uniform/RandomUniform}} was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssign: CPU \nApplyGradientDescent: CPU \nRandomUniform: CPU XLA_CPU XLA_GPU \nConst: CPU XLA_CPU XLA_GPU \nMul: CPU XLA_CPU XLA_GPU \nSub: CPU XLA_CPU XLA_GPU \nAdd: CPU XLA_CPU XLA_GPU \nIdentity: CPU XLA_CPU XLA_GPU \nVariableV2: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  W/Initializer/random_uniform/shape (Const) \n  W/Initializer/random_uniform/min (Const) \n  W/Initializer/random_uniform/max (Const) \n  W/Initializer/random_uniform/RandomUniform (RandomUniform) \n  W/Initializer/random_uniform/sub (Sub) \n  W/Initializer/random_uniform/mul (Mul) \n  W/Initializer/random_uniform (Add) \n  W (VariableV2) /device:GPU:0\n  W/Assign (Assign) /device:GPU:0\n  W/read (Identity) /device:GPU:0\n  GradientDescent/update_W/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n\n\t [[{{node W/Initializer/random_uniform/RandomUniform}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-298df1d72c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2437\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     \"\"\"\n\u001b[0;32m-> 2439\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5440\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5442\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation W/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node node W/Initializer/random_uniform/RandomUniform (defined at /home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) placed on device Device assignments active during op 'W/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:1816>\n  with tf.device(/GPU:0): <<ipython-input-9-298df1d72c53>:18>  was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssign: CPU \nApplyGradientDescent: CPU \nRandomUniform: CPU XLA_CPU XLA_GPU \nConst: CPU XLA_CPU XLA_GPU \nMul: CPU XLA_CPU XLA_GPU \nSub: CPU XLA_CPU XLA_GPU \nAdd: CPU XLA_CPU XLA_GPU \nIdentity: CPU XLA_CPU XLA_GPU \nVariableV2: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  W/Initializer/random_uniform/shape (Const) \n  W/Initializer/random_uniform/min (Const) \n  W/Initializer/random_uniform/max (Const) \n  W/Initializer/random_uniform/RandomUniform (RandomUniform) \n  W/Initializer/random_uniform/sub (Sub) \n  W/Initializer/random_uniform/mul (Mul) \n  W/Initializer/random_uniform (Add) \n  W (VariableV2) /device:GPU:0\n  W/Assign (Assign) /device:GPU:0\n  W/read (Identity) /device:GPU:0\n  GradientDescent/update_W/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n\n\t [[node W/Initializer/random_uniform/RandomUniform (defined at /home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]Additional information about colocations:No node-device colocations were active during op 'W/Initializer/random_uniform/RandomUniform' creation.\nDevice assignments active during op 'W/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:1816>\n  with tf.device(/GPU:0): <<ipython-input-9-298df1d72c53>:18>\n\nOriginal stack trace for 'W/Initializer/random_uniform/RandomUniform':\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-298df1d72c53>\", line 26, in <module>\n    initializer=tf.random_uniform_initializer(-1.0,1.0))\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n    shape=shape)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n    shape=shape)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 1818, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 905, in <lambda>\n    partition_info=partition_info)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py\", line 283, in __call__\n    shape, self.minval, self.maxval, dtype, seed=self.seed)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/random_ops.py\", line 245, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_random_ops.py\", line 822, in random_uniform\n    name=name)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/donghyun/anaconda2/envs/RL_STUDY/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Every-visit Monte Carlro Policy Evaluation for V\n",
    "\n",
    "tf.reset_default_graph()\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"Tensorflow version : \")\n",
    "print(tf.__version__)\n",
    "print()\n",
    "\n",
    "\n",
    "## set HyperParemeters\n",
    "epoch = 1000\n",
    "lr_rate = 0.01\n",
    "policy = optimalWithNoise_policy # Evaluation -> follow given policy\n",
    "## MC evaluation\n",
    "num_visit = np.zeros(N_STATES) # N(s)\n",
    "cum_gain = np.zeros(N_STATES) # S(s)\n",
    "with tf.device('/cpu:0'):\n",
    "    ## set tensorflow variable\n",
    "    state_tf = tf.placeholder(tf.int32,shape=[None],name = \"state\")\n",
    "    gain_tf = tf.placeholder(tf.float32,shape=[None],name = 'gain')\n",
    "    #### number state -> matrix ex. 3 -> [0 0 0 1 0 0 0 0 0 0 0]\n",
    "    W = tf.get_variable(name='W', \\\n",
    "                        shape = [N_STATES,1],\\\n",
    "                        dtype = tf.float32, \\\n",
    "                        initializer=tf.random_uniform_initializer(-1.0,1.0))\n",
    "state_tf_one_hot = tf.one_hot(state_tf,N_STATES)\n",
    "V = tf.matmul(state_tf_one_hot, W) # linear combination reprentaion of state value function\n",
    "MC_error = gain_tf - V\n",
    "loss = tf.reduce_mean(tf.square(MC_error)) #mean-square-error\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=lr_rate)\n",
    "train_ops = opt.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        \n",
    "        #print(str(_+1)+\"th iteration\")\n",
    "        done = False\n",
    "        reward_history = []\n",
    "        simulation_history = []\n",
    "        gain_history = []   \n",
    "        s = np.random.choice(start_state) # random initial state\n",
    "        \n",
    "        while not done:\n",
    "            simulation_history.append(s)\n",
    "            a = np.random.choice(actions,p=policy[s,:])\n",
    "            reward_history.append(R[s,a])\n",
    "            s1 = np.random.choice(states,p=P[s,a,:])\n",
    "            \n",
    "            if s1 in terminal_state:\n",
    "                done = True\n",
    "                simulation_history.append(s1)\n",
    "                reward_history.append(R[s1,0])\n",
    "            \n",
    "            else:\n",
    "                s = s1\n",
    "                \n",
    "        # After finish one simulation update value function -> offline\n",
    "        # evaluate G(t)\n",
    "        for i,r in enumerate(reward_history[::-1]):\n",
    "            # G(t-1) = reward(t) + gamma * G(t)\n",
    "            # if terminal G(T) = r(T)\n",
    "            # To implent, i use reverse ordering\n",
    "            if i==0:\n",
    "                gain_history.append(r)\n",
    "            else:\n",
    "                gain_history.append(gamma * gain_history[i-1] + r)\n",
    "\n",
    "        gain_history = gain_history[::-1]\n",
    "        ##-------------------- This is for Exact MC\n",
    "        # add G(t) to s(t)\n",
    "        for i,s in enumerate(simulation_history):\n",
    "            # i for find G(t)\n",
    "            # S(s) = S(s) + G(t) for only first visit.\n",
    "            num_visit[s]+=1\n",
    "            cum_gain[s]= cum_gain[s] + gain_history[i]\n",
    "        ##-------------------- This is for Function approximation MC\n",
    "        for i in range(len(simulation_history)):\n",
    "            feed_dict = {state_tf: [simulation_history[i]],\\\n",
    "                        gain_tf: [gain_history[i]]}\n",
    "            sess.run(train_ops, feed_dict=feed_dict)\n",
    "    # after finish all epoch\n",
    "    V_final=[]\n",
    "    for s in states:\n",
    "        feed_dict = {state_tf: [s]}\n",
    "        V_now = sess.run(V,feed_dict=feed_dict)\n",
    "        V_final.append(V_now[0][0])\n",
    "    print(\"Function Approximation result\")\n",
    "    print(V_final)\n",
    "V = np.zeros(N_STATES)\n",
    "V = cum_gain/(num_visit+1.0e-8)\n",
    "print()\n",
    "print()\n",
    "print(\"Exact Value Function from MC\")\n",
    "print(V)\n",
    "print()\n",
    "print()\n",
    "print(\"it takes \"+str(round(time.time()-start))+\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : \n",
      "1.5.0\n",
      "\n",
      "Function Approximation result\n",
      "[[ 0.76324111  0.79037249  0.77992487  0.69187081]\n",
      " [ 0.8347652   0.86189657  0.85144901  0.76339489]\n",
      " [ 0.91392899  0.9410603   0.93061274  0.84255862]\n",
      " [ 1.01648712  1.04361844  1.03317094  0.94511676]\n",
      " [ 0.77556163  0.80269301  0.79224539  0.70419133]\n",
      " [ 0.51105231  0.53818369  0.52773613  0.43968201]\n",
      " [-0.54534531 -0.51821393 -0.52866149 -0.61671561]\n",
      " [ 0.75443184  0.78156316  0.77111566  0.68306148]\n",
      " [ 0.71992838  0.7470597   0.73661214  0.64855802]\n",
      " [ 0.70071876  0.72785008  0.71740258  0.6293484 ]\n",
      " [ 0.41266191  0.43979326  0.4293457   0.34129158]]\n",
      "it takes 7 sec\n"
     ]
    }
   ],
   "source": [
    "# Every-visit Monte Carlro Policy Evaluation for Q\n",
    "\n",
    "tf.reset_default_graph()\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"Tensorflow version : \")\n",
    "print(tf.__version__)\n",
    "print()\n",
    "\n",
    "\n",
    "## set HyperParemeters\n",
    "epoch = 1000\n",
    "lr_rate = 0.01\n",
    "policy = optimalWithNoise_policy # Evaluation -> follow given policy\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    ## set tensorflow variable\n",
    "    state_tf = tf.placeholder(tf.int32,shape=[None],name = \"state\")\n",
    "    action_tf = tf.placeholder(tf.int32,shape=[None],name = \"action\")\n",
    "    gain_tf = tf.placeholder(tf.float32,shape=[None],name = 'gain')\n",
    "    #### number state -> matrix ex. 3 -> [0 0 0 1 0 0 0 0 0 0 0]\n",
    "    W = tf.get_variable(name='W', \\\n",
    "                        shape = [N_STATES+N_ACTIONS,1],\\\n",
    "                        dtype = tf.float32, \\\n",
    "                        initializer=tf.random_uniform_initializer(-1.0,1.0))\n",
    "state_tf_one_hot = tf.one_hot(state_tf,N_STATES)\n",
    "action_tf_one_hot = tf.one_hot(action_tf,N_ACTIONS)\n",
    "\n",
    "state_action_tf_one_hot = tf.concat([state_tf_one_hot, action_tf_one_hot], 1)\n",
    "\n",
    "Q = tf.matmul(state_action_tf_one_hot, W) # linear combination reprentaion of state value function\n",
    "MC_error = gain_tf - Q\n",
    "loss = tf.reduce_mean(tf.square(MC_error)) #mean-square-error\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=lr_rate)\n",
    "train_ops = opt.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        reward_history = []\n",
    "        simulation_history = []\n",
    "        gain_history = []   \n",
    "        #print(str(_+1)+\"th iteration\")\n",
    "        done = False\n",
    "        s = np.random.choice(start_state) # random initial state\n",
    "        \n",
    "        while not done:\n",
    "            simulation_history.append((s,a))\n",
    "            a = np.random.choice(actions,p=policy[s,:])\n",
    "            reward_history.append(R[s,a])\n",
    "            s1 = np.random.choice(states,p=P[s,a,:])\n",
    "            \n",
    "            if s1 in terminal_state:\n",
    "                done = True\n",
    "                simulation_history.append((s1,0))\n",
    "                reward_history.append(R[s1,0])\n",
    "            \n",
    "            else:\n",
    "                s = s1\n",
    "                \n",
    "        # After finish one simulation update value function -> offline\n",
    "        # evaluate G(t)\n",
    "        for i,r in enumerate(reward_history[::-1]):\n",
    "            # G(t-1) = reward(t) + gamma * G(t)\n",
    "            # if terminal G(T) = r(T)\n",
    "            # To implent, i use reverse ordering\n",
    "            if i==0:\n",
    "                gain_history.append(r)\n",
    "            else:\n",
    "                gain_history.append(gamma * gain_history[i-1] + r)\n",
    "\n",
    "        gain_history = gain_history[::-1]\n",
    "\n",
    "        ##-------------------- This is for Function approximation MC\n",
    "        for i,(s,a) in enumerate(simulation_history):\n",
    "            feed_dict = {state_tf: [s],\\\n",
    "                         action_tf: [a],\\\n",
    "                        gain_tf: [gain_history[i]]}\n",
    "            sess.run(train_ops, feed_dict=feed_dict)\n",
    "            \n",
    "    # after finish all epoch\n",
    "    Q_final= np.empty((N_STATES,N_ACTIONS))\n",
    "    for s in states:\n",
    "        for a in actions:\n",
    "            feed_dict = {state_tf: [s],action_tf: [a]}\n",
    "            Q_now = sess.run(Q,feed_dict=feed_dict)\n",
    "            Q_final[s,a] = Q_now[0][0]\n",
    "    print(\"Function Approximation result\")\n",
    "    print(Q_final)\n",
    "\n",
    "print(\"it takes \"+str(round(time.time()-start))+\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
